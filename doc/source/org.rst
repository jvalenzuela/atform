Organization
============

.. _section:

Sectioning
----------

By default, |project_name| will automatically number tests with single,
increasing integer;
simple, yet often insufficient. Most projects will need
additional organizational levels to segregate related test procedures into
sections, and |project_name| can support this by numbering tests
with multiple integer fields,
e.g., 5.1 or 1.8.9. Any quantity of fields can be used,
although practical values are between two and four. The only stipulation
regarding numbering is all test procedures must use the same format,
i.e., *every* test will be numbered with the same quantity of fields.

When using two or more numbering fields, |project_name| refers to each field as a
level, with the leftmost field as level one, increasing up to
the number of configured levels. For example, when configured for
three levels, tests will be numbered *x.y.z*; where *x* is level one, *y* is
level two, and *z* is level three.

The following example shows the two commands for organizing tests
into sections:
:py:func:`atform.set_id_depth` and
:py:func:`atform.section`:

.. literalinclude:: examples/section.py
   :caption: Excerpt of section.py
   :start-after: # begin-listing
   :end-before: # end-listing


.. _skip:

Skipping Tests
--------------

Having tests automatically numbered is generally helpful, alleviating the
task of manually enumerating tests and sections, however, there are
some circumstances where the author must intervene. The most common
cases are reserving a range of numbers for future use, or removing a
defunct test without affecting later ones. The following example illustrates
some different methods of skipping numbers:

.. literalinclude:: examples/skip.py
   :caption: Excerpt of skip.py
   :start-after: # begin-listing
   :end-before: # end-listing


Source Files
------------

Another tactic for organizing test procedures is to split them into separate
scripts. Dividing large constructs into smaller components, each within their
own file is common in many domains, including documentation. This approach
makes it easier to locate content, and for multiple authors to work on tests
simultaneously. Separating tests into multiple scripts, however, does not
affect the output; tests are numbered in the order they are encountered
regardless of how many source files are involved.

Organizing tests into multiple scripts utilizes Python's :code:`import` keyword.
The examples so far use :code:`import atform` to load |project_name|;
separate scripts, each containing their own set of tests, e.g., one script
per section, can be imported in a similar fashion. The recommended way to
do this is to arrange scripts heirarchically, with one script at the top-level
containing the setup and output areas, and the actual test content
imported from one or more lower-level scripts. The example below shows
a top-level script that imports content from two, separate files:

.. literalinclude:: examples/main.py
   :caption: Excerpt of main.py
   :start-after: # begin-listing
   :end-before: # end-listing

Next are the scripts imported from the main script, illustrating how
content can be distributed into the lower-level scripts:

.. literalinclude:: examples/button.py
   :caption: button.py

.. literalinclude:: examples/switch.py
   :caption: switch.py

When generating PDF output for tests in multiple files, execute the top-level
script only, which will automatically incorporate any imported scripts.
All tests in the example above would be generated by running
:command:`python main.py`.


.. _idlock:

Numbering Protection
--------------------

The automatic numbering system eliminates the need to manually increment
numeric identifiers assigned to each test, however, its implicit
operation also makes it easy for modifications to inadvertently
shift identifiers assigned to existing tests. For example, adding tests
in the middle of a script may affect identifiers assigned to tests
defined afterwards. Altering existing test numbering is often unacceptable,
especially after those documents enter circulation.

The |project_name| package implements a mechanism to help mitigate this
type of error by storing the identifier and title for each test in
an external file, hereafter referred to as the *lock file*.
Each time the script is executed the lock file is read, its content compared to
the current set of tests, and an error reported if any tests were found
to have shifted.

The lock file is named |idlock_filename|, and is located in the root
project folder. It uses the comma-separated variable, or CSV, format,
however, it should *not* be created or edited externally; always let
|project_name| create the lock file using the process described here.
An important detail regarding the lock file is |project_name| will *only*
create it if it does not exist, i.e., |project_name| will not overwrite
an existing lock file. This is intentional, serving to ensure the lock
file is only altered when explicitly allowed by the user. To generate a
lock file, simply delete the existing one and run the script.

The lock file should be left in place when making changes where the intent
is not to alter existing test numbering or titles. This includes completely
removing tests so long as it doesn't affect the numbering of surrounding
tests. Keeping the original lock file during the edit and review
process allows |project_name| to detect and prevent unintentional shifts.
Once the changes are deemed acceptable, the lock file can be updated by
deleting it and running the script.

Changing the number or title of a test stored in the lock file requires
the lock file to be deleted before the script is run; differences in
existing test identifiers or titles would otherwise generate an error
and prevent building output PDF files.

When using a version control system, the lock file should be committed
just like any other source file. Each row of the lock file lists a
single test identifier and title, making the impact of each change readily
apparent using diff tools that typically accompany version control
software.

The features described in :ref:`cli` do not affect the title and number
verification process. In other words, all tests are subjected to lock
file comparison regardless of any optional output filtering.
This independence extends to content stored in the lock file in that
it always contains the complete set of tests, and can be leveraged to quickly
build a lock file by reducing the number of output PDFs.

The lock file format is specific to each version of |project_name|,
requiring the lock file to be rebuilt when updating to a different version.
